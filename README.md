# VLM-self-correction

## Abstract

Recently, LLM's ability to self-correction in reasoning tasks has been discussed in solving natural language questions, centering around mathematics and question answering. Nevertheless, the ability to self-correction multimodal AI systems has not been discussed intensively. On the one hand, the self-correction ability of LLMs on reasoning tasks is still disputable. On the other hand, multimodal AI systems are more complicated than purely language-based models, involving the fusion of different modalities and then producing outputs based on the fusions. Therefore, self-correction on multimodal AI systems is a challenge for us to solve. In this project, the authors experimented with several methods to try to improve the VLM's self-correction ability with hints and finetuning. Please refer to the project report for more details. Thanks!

## Important Notes
The project is done. Codes for the first inference are stored in files named with new_inference. 

Codes of the second round of inference are stored in the second_round_new_infernce... 

A results summary is generated using find_percentage_second.py. 

All the results are stored in the result_summary.txt

However, the generated data is too large to upload. However, if they are required, we can provide them 
by uploading to Google Drive.

